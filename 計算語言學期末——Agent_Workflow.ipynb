{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcqR32HGA7Xc"
      },
      "source": [
        "\n",
        "# æ¨™é¡Œï¼šå¥½åƒè¦å¯«äº›ä»€éº¼å¾ˆå²å®³çš„æ±è¥¿ã€‚\n",
        "---\n",
        "\n",
        "## To-do list\n",
        "### A tier: ç·Šæ€¥ä¸”é‡è¦\n",
        "- LM-AIG loop\n",
        "- æ”¶é›†æ¸¬é©—æ•¸æ“š\n",
        "- å¯« System Prompt\n",
        "### B tier: é‡è¦ä½†ä¸ç·Šæ€¥\n",
        "- Searching Agent\n",
        "- Data-analysis pipeline\n",
        "### C tier: ç·Šæ€¥ä½†ä¸é‡è¦\n",
        "- é¸æ¨¡å‹ï¼ŒåŸå§‹ç ”ç©¶ä½¿ç”¨ GPT-4oã€‚æˆ‘å€‘å¯ä»¥æ”¹ç”¨ instruct model?\n",
        "### D tier: ä¸é‡è¦ä¹Ÿä¸ç·Šæ€¥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXn2CVaqBS1e"
      },
      "source": [
        "## æœç´¢è³‡æ–™ Agent\n",
        "\n",
        "ï¼ˆä¹Ÿè¨±é€™å€‹æ­¥é©Ÿå¯ä»¥ç•¶ä½œå¯é¸çš„ï¼Œä¸å¼·è¿«é€²è¡Œæœç´¢ã€‚ï¼‰\n",
        "\n",
        "æ¥æ”¶ Prompt ä¸¦é€é Perplexity APIï¼ˆæˆ–å…¶ä»–æ±è¥¿ï¼‰æœç´¢ç¶²è·¯ã€‚\n",
        "\n",
        "å°‡æœç´¢çµæœæä¾›çµ¦ä½¿ç”¨è€…åšè©•ä¼°ï¼Œè‹¥ä½¿ç”¨è€…ä¸æ¥å—å°±é‡æ–°é€²è¡Œæœç´¢ã€‚\n",
        "\n",
        "å°‡æœç´¢çµæœä½œç‚º Prompt å‚³çµ¦ LM-AIG ä¸¦é–‹å§‹ç·¨è£½æ¸¬é©—ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qPVV2xe7A2MV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ AI è‡ªå‹•å‡ºé¡Œç³»çµ±åˆå§‹åŒ–å®Œæˆï¼\n",
            "ä½¿ç”¨æ¨¡å‹: llama3.2:1b\n",
            "âœ… Ollama æœå‹™æ­£å¸¸\n",
            "å·²å®‰è£æ¨¡å‹: ['', '', '', '']\n",
            "âœ… æ¨¡å‹ llama3.2:1b æ¸¬è©¦æˆåŠŸï¼\n",
            "æ¸¬è©¦å›æ‡‰: System ready. What would you like to do?\n",
            "âœ… æ¨¡å‹ llama3.2:1b æ¸¬è©¦æˆåŠŸï¼\n",
            "æ¸¬è©¦å›æ‡‰: System ready. What would you like to do?\n"
          ]
        }
      ],
      "source": [
        "# å°å…¥å¿…è¦çš„å¥—ä»¶\n",
        "import ollama\n",
        "import json\n",
        "import requests\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "import time\n",
        "import re\n",
        "\n",
        "# è¨­å®šåŸºæœ¬é…ç½®\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"ç³»çµ±é…ç½®é¡åˆ¥\"\"\"\n",
        "    model_name: str = \"llama3.2:1b\"  # ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹\n",
        "    temperature: float = 0.7\n",
        "    max_tokens: int = 1000\n",
        "    \n",
        "config = Config()\n",
        "\n",
        "print(\"ğŸš€ AI è‡ªå‹•å‡ºé¡Œç³»çµ±åˆå§‹åŒ–å®Œæˆï¼\")\n",
        "print(f\"ä½¿ç”¨æ¨¡å‹: {config.model_name}\")\n",
        "\n",
        "# æª¢æŸ¥ Ollama æœå‹™æ˜¯å¦é‹è¡Œ\n",
        "try:\n",
        "    models_response = ollama.list()\n",
        "    print(f\"âœ… Ollama æœå‹™æ­£å¸¸\")\n",
        "    \n",
        "    # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨\n",
        "    available_models = []\n",
        "    if 'models' in models_response:\n",
        "        available_models = [model.get('name', '') for model in models_response['models']]\n",
        "    \n",
        "    print(f\"å·²å®‰è£æ¨¡å‹: {available_models}\")\n",
        "    \n",
        "    # æ¸¬è©¦æ¨¡å‹èª¿ç”¨\n",
        "    test_response = ollama.chat(\n",
        "        model=config.model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Hello, please respond with 'System ready'\"}],\n",
        "        options={\"temperature\": 0.1, \"num_predict\": 10}\n",
        "    )\n",
        "    \n",
        "    if test_response and 'message' in test_response:\n",
        "        print(f\"âœ… æ¨¡å‹ {config.model_name} æ¸¬è©¦æˆåŠŸï¼\")\n",
        "        print(f\"æ¸¬è©¦å›æ‡‰: {test_response['message']['content']}\")\n",
        "    else:\n",
        "        print(\"âš ï¸  æ¨¡å‹å›æ‡‰æ ¼å¼ç•°å¸¸\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Ollama é€£æ¥å¤±æ•—: {e}\")\n",
        "    print(\"è«‹ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œä¸¦ä¸”æ¨¡å‹å·²å®‰è£\")\n",
        "    print(\"å¯ä»¥å˜—è©¦é‹è¡Œ: ollama pull llama3.2:1b\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlZsYWLIBWpw"
      },
      "source": [
        "## LM-AIG loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt09pt3bBf2h"
      },
      "source": [
        "### Item Writing Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sahJQNH1BZYP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ItemWritingAgent å·²åˆå§‹åŒ–å®Œæˆï¼\n"
          ]
        }
      ],
      "source": [
        "class ItemWritingAgent():\n",
        "    \"\"\"\n",
        "    åŸºæ–¼ Ollama çš„é¡Œç›®ç”Ÿæˆä»£ç†äººï¼Œæ ¹æ“šä½¿ç”¨è€…è¦æ ¼ä½¿ç”¨æŒ‡å®šèªè¨€æ¨¡å‹ç”Ÿæˆæ¸¬é©—é¡Œç›®ã€‚\n",
        "    \"\"\"\n",
        "    def __init__(self, model: str = None, system_prompt: str = None):\n",
        "        self.model = model or config.model_name\n",
        "        self.system_prompt = system_prompt or self._default_system_prompt()\n",
        "        \n",
        "    def _default_system_prompt(self) -> str:\n",
        "        \"\"\"é è¨­çš„ç³»çµ±æç¤ºè©\"\"\"\n",
        "        return \"\"\"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å¿ƒç†æ¸¬é©—é¡Œç›®ç·¨å¯«å°ˆå®¶ã€‚è«‹æ ¹æ“šä½¿ç”¨è€…çš„éœ€æ±‚ï¼Œç”Ÿæˆé«˜å“è³ªçš„æ¸¬é©—é¡Œç›®ã€‚\n",
        "\n",
        "ç”Ÿæˆè¦å‰‡ï¼š\n",
        "1. æ¯å€‹é¡Œç›®éƒ½æ‡‰è©²æœ‰æ˜ç¢ºçš„å¿ƒç†å­¸ç†è«–åŸºç¤\n",
        "2. é¡Œç›®èªè¨€æ‡‰è©²æ¸…æ™°ã€ç„¡æ­§ç¾©\n",
        "3. é¿å…æ–‡åŒ–åè¦‹å’Œäººå£å­¸åè¦‹\n",
        "4. é¡Œç›®é›£åº¦æ‡‰è©²é©ä¸­\n",
        "5. æä¾›å¤šå€‹é¸é …ï¼ˆå¦‚æœæ˜¯é¸æ“‡é¡Œï¼‰\n",
        "\n",
        "è¼¸å‡ºæ ¼å¼ï¼š\n",
        "è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š\n",
        "- items: é¡Œç›®åˆ—è¡¨\n",
        "- item_type: é¡Œç›®é¡å‹ï¼ˆå¦‚ï¼šlikert, multiple_choice, open_endedï¼‰\n",
        "- psychological_construct: å¿ƒç†å»ºæ§‹\n",
        "- difficulty_level: é›£åº¦ç­‰ç´šï¼ˆ1-5ï¼‰\n",
        "\"\"\"\n",
        "\n",
        "    def generate_items(self, specifications: str, num_items: int = 5) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        æ ¹æ“šè¦æ ¼ç”Ÿæˆæ¸¬é©—é¡Œç›®\n",
        "\n",
        "        Args:\n",
        "            specifications (str): ä½¿ç”¨è€…å°æ¸¬é©—é¡Œç›®çš„è¦æ ¼è¦æ±‚\n",
        "            num_items (int): è¦ç”Ÿæˆçš„é¡Œç›®æ•¸é‡\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: ç”Ÿæˆçš„é¡Œç›®è³‡æ–™\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # æ§‹å»ºå®Œæ•´çš„æç¤ºè©\n",
        "            user_prompt = f\"\"\"\n",
        "è«‹æ ¹æ“šä»¥ä¸‹è¦æ ¼ç”Ÿæˆ {num_items} å€‹å¿ƒç†æ¸¬é©—é¡Œç›®ï¼š\n",
        "\n",
        "è¦æ ¼è¦æ±‚ï¼š\n",
        "{specifications}\n",
        "\n",
        "è«‹åš´æ ¼æŒ‰ç…§ JSON æ ¼å¼è¼¸å‡ºçµæœã€‚\n",
        "\"\"\"\n",
        "            \n",
        "            # èª¿ç”¨ Ollama API\n",
        "            response = ollama.chat(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": user_prompt}\n",
        "                ],\n",
        "                options={\n",
        "                    \"temperature\": config.temperature,\n",
        "                    \"num_predict\": config.max_tokens\n",
        "                }\n",
        "            )\n",
        "            \n",
        "            # è§£æå›æ‡‰\n",
        "            content = response['message']['content']\n",
        "            \n",
        "            # å˜—è©¦è§£æ JSON\n",
        "            try:\n",
        "                # æå– JSON éƒ¨åˆ†\n",
        "                json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
        "                if json_match:\n",
        "                    result = json.loads(json_match.group())\n",
        "                else:\n",
        "                    # å¦‚æœç„¡æ³•è§£æï¼Œå›å‚³åŸå§‹æ–‡æœ¬\n",
        "                    result = {\"raw_output\": content, \"items\": [content]}\n",
        "            except json.JSONDecodeError:\n",
        "                result = {\"raw_output\": content, \"items\": [content]}\n",
        "            \n",
        "            return result\n",
        "            \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"error\": f\"ç”Ÿæˆé¡Œç›®æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\",\n",
        "                \"items\": []\n",
        "            }\n",
        "    \n",
        "    def refine_items(self, items: List[str], feedback: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        æ ¹æ“šå›é¥‹æ”¹é€²é¡Œç›®\n",
        "        \n",
        "        Args:\n",
        "            items: åŸå§‹é¡Œç›®åˆ—è¡¨\n",
        "            feedback: æ”¹é€²å»ºè­°\n",
        "            \n",
        "        Returns:\n",
        "            æ”¹é€²å¾Œçš„é¡Œç›®\n",
        "        \"\"\"\n",
        "        try:\n",
        "            refine_prompt = f\"\"\"\n",
        "è«‹æ ¹æ“šä»¥ä¸‹å›é¥‹æ”¹é€²é€™äº›å¿ƒç†æ¸¬é©—é¡Œç›®ï¼š\n",
        "\n",
        "åŸå§‹é¡Œç›®ï¼š\n",
        "{json.dumps(items, ensure_ascii=False, indent=2)}\n",
        "\n",
        "æ”¹é€²å»ºè­°ï¼š\n",
        "{feedback}\n",
        "\n",
        "è«‹è¼¸å‡ºæ”¹é€²å¾Œçš„é¡Œç›®ï¼ˆJSON æ ¼å¼ï¼‰ã€‚\n",
        "\"\"\"\n",
        "            \n",
        "            response = ollama.chat(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": refine_prompt}\n",
        "                ],\n",
        "                options={\n",
        "                    \"temperature\": config.temperature,\n",
        "                    \"num_predict\": config.max_tokens\n",
        "                }\n",
        "            )\n",
        "            \n",
        "            content = response['message']['content']\n",
        "            \n",
        "            # å˜—è©¦è§£æ JSON\n",
        "            try:\n",
        "                json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
        "                if json_match:\n",
        "                    result = json.loads(json_match.group())\n",
        "                else:\n",
        "                    result = {\"raw_output\": content, \"items\": [content]}\n",
        "            except json.JSONDecodeError:\n",
        "                result = {\"raw_output\": content, \"items\": [content]}\n",
        "            \n",
        "            return result\n",
        "            \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"error\": f\"æ”¹é€²é¡Œç›®æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\",\n",
        "                \"items\": items\n",
        "            }\n",
        "\n",
        "# å»ºç«‹é¡Œç›®ç”Ÿæˆå™¨å¯¦ä¾‹\n",
        "item_writer = ItemWritingAgent()\n",
        "print(\"âœ… ItemWritingAgent å·²åˆå§‹åŒ–å®Œæˆï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjHFGrcqBjhc"
      },
      "source": [
        "### Critic Agent\n",
        "\n",
        "åŒ…å«\n",
        "- Content Reviewer Agent: è©•ä¼°å…§å®¹æ•ˆåº¦ã€‚\n",
        "- Linguistic Reviewer Agent: æª¢æŸ¥é¡Œç›®çš„å¯è®€æ€§èˆ‡é€šé †åº¦ã€‚\n",
        "- Bias Reviewer Agent: æª¢æŸ¥æ˜¯å¦æœ‰äººå£å­¸ä¸Šçš„åè¦‹å•é¡Œã€‚\n",
        "- Meta Reviewer Agent: æ•´åˆä¸¦å›é¥‹çµ¦ Critic Agentã€‚\n",
        "\n",
        "Critic Agent åœ¨æ ¡æ­£å®Œä¹‹å¾Œï¼Œå†å°‡çµæœå›å‚³çµ¦ä½¿ç”¨è€…æä¾›å›é¥‹ã€‚è‹¥ä½¿ç”¨è€…èªç‚ºéœ€è¦ä¿®æ”¹ï¼Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… CriticAgent å·²åˆå§‹åŒ–å®Œæˆï¼\n"
          ]
        }
      ],
      "source": [
        "class CriticAgent:\n",
        "    \"\"\"\n",
        "    è©•å¯©ä»£ç†äººï¼ŒåŒ…å«å¤šå€‹å­è©•å¯©å“¡ä¾†è©•ä¼°æ¸¬é©—é¡Œç›®çš„å“è³ª\n",
        "    \"\"\"\n",
        "    def __init__(self, model: str = None):\n",
        "        self.model = model or config.model_name\n",
        "        self.content_reviewer = ContentReviewer(self.model)\n",
        "        self.linguistic_reviewer = LinguisticReviewer(self.model)\n",
        "        self.bias_reviewer = BiasReviewer(self.model)\n",
        "        self.meta_reviewer = MetaReviewer(self.model)\n",
        "    \n",
        "    def review_items(self, items: List[str], construct: str = \"\") -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        å…¨é¢è©•å¯©æ¸¬é©—é¡Œç›®\n",
        "        \n",
        "        Args:\n",
        "            items: é¡Œç›®åˆ—è¡¨\n",
        "            construct: å¿ƒç†å»ºæ§‹åç¨±\n",
        "            \n",
        "        Returns:\n",
        "            è©•å¯©çµæœ\n",
        "        \"\"\"\n",
        "        print(\"ğŸ” é–‹å§‹å…¨é¢è©•å¯©æ¸¬é©—é¡Œç›®...\")\n",
        "        \n",
        "        # å„å­è©•å¯©å“¡çš„è©•å¯©çµæœ\n",
        "        reviews = {\n",
        "            \"content_review\": self.content_reviewer.review(items, construct),\n",
        "            \"linguistic_review\": self.linguistic_reviewer.review(items),\n",
        "            \"bias_review\": self.bias_reviewer.review(items),\n",
        "        }\n",
        "        \n",
        "        # å…ƒè©•å¯©å“¡æ•´åˆæ‰€æœ‰è©•å¯©çµæœ\n",
        "        meta_review = self.meta_reviewer.integrate_reviews(reviews, items)\n",
        "        \n",
        "        return {\n",
        "            \"individual_reviews\": reviews,\n",
        "            \"meta_review\": meta_review,\n",
        "            \"overall_score\": meta_review.get(\"overall_score\", 0),\n",
        "            \"recommendations\": meta_review.get(\"recommendations\", [])\n",
        "        }\n",
        "\n",
        "class ContentReviewer:\n",
        "    \"\"\"å…§å®¹æ•ˆåº¦è©•å¯©å“¡\"\"\"\n",
        "    \n",
        "    def __init__(self, model: str):\n",
        "        self.model = model\n",
        "        \n",
        "    def review(self, items: List[str], construct: str) -> Dict[str, Any]:\n",
        "        \"\"\"è©•ä¼°å…§å®¹æ•ˆåº¦\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "ä½ æ˜¯å¿ƒç†æ¸¬é©—å…§å®¹æ•ˆåº¦å°ˆå®¶ã€‚è«‹è©•ä¼°ä»¥ä¸‹é¡Œç›®æ˜¯å¦èƒ½æœ‰æ•ˆæ¸¬é‡æŒ‡å®šçš„å¿ƒç†å»ºæ§‹ã€‚\n",
        "\n",
        "å¿ƒç†å»ºæ§‹: {construct}\n",
        "é¡Œç›®åˆ—è¡¨:\n",
        "{json.dumps(items, ensure_ascii=False, indent=2)}\n",
        "\n",
        "è«‹è©•ä¼°ï¼š\n",
        "1. é¡Œç›®æ˜¯å¦èˆ‡å¿ƒç†å»ºæ§‹ç›¸é—œ\n",
        "2. é¡Œç›®æ˜¯å¦æ¶µè“‹è©²å»ºæ§‹çš„é‡è¦é¢å‘\n",
        "3. é¡Œç›®çš„ç†è«–åŸºç¤æ˜¯å¦å……åˆ†\n",
        "\n",
        "è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºè©•ä¼°çµæœï¼ŒåŒ…å«ï¼š\n",
        "- validity_score: æ•ˆåº¦åˆ†æ•¸ (1-10)\n",
        "- strengths: å„ªé»åˆ—è¡¨\n",
        "- weaknesses: ç¼ºé»åˆ—è¡¨\n",
        "- suggestions: æ”¹é€²å»ºè­°\n",
        "\"\"\"\n",
        "        \n",
        "        return self._get_review_response(prompt)\n",
        "    \n",
        "    def _get_review_response(self, prompt: str) -> Dict[str, Any]:\n",
        "        \"\"\"ç²å–è©•å¯©å›æ‡‰\"\"\"\n",
        "        try:\n",
        "            response = ollama.chat(\n",
        "                model=self.model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                options={\"temperature\": 0.3}\n",
        "            )\n",
        "            \n",
        "            content = response['message']['content']\n",
        "            \n",
        "            # å˜—è©¦è§£æ JSON\n",
        "            try:\n",
        "                json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
        "                if json_match:\n",
        "                    result = json.loads(json_match.group())\n",
        "                else:\n",
        "                    result = {\"raw_output\": content, \"validity_score\": 5}\n",
        "            except json.JSONDecodeError:\n",
        "                result = {\"raw_output\": content, \"validity_score\": 5}\n",
        "            \n",
        "            return result\n",
        "            \n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e), \"validity_score\": 0}\n",
        "\n",
        "class LinguisticReviewer:\n",
        "    \"\"\"èªè¨€å­¸è©•å¯©å“¡\"\"\"\n",
        "    \n",
        "    def __init__(self, model: str):\n",
        "        self.model = model\n",
        "        \n",
        "    def review(self, items: List[str]) -> Dict[str, Any]:\n",
        "        \"\"\"è©•ä¼°é¡Œç›®çš„èªè¨€å“è³ª\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "ä½ æ˜¯èªè¨€å­¸å°ˆå®¶ã€‚è«‹è©•ä¼°ä»¥ä¸‹æ¸¬é©—é¡Œç›®çš„èªè¨€å“è³ªã€‚\n",
        "\n",
        "é¡Œç›®åˆ—è¡¨:\n",
        "{json.dumps(items, ensure_ascii=False, indent=2)}\n",
        "\n",
        "è«‹è©•ä¼°ï¼š\n",
        "1. èªè¨€æ˜¯å¦æ¸…æ™°æ˜“æ‡‚\n",
        "2. æ˜¯å¦æœ‰èªæ³•éŒ¯èª¤\n",
        "3. ç”¨è©æ˜¯å¦æ°ç•¶\n",
        "4. æ˜¯å¦æœ‰æ­§ç¾©è¡¨é”\n",
        "\n",
        "è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºè©•ä¼°çµæœï¼ŒåŒ…å«ï¼š\n",
        "- readability_score: å¯è®€æ€§åˆ†æ•¸ (1-10)\n",
        "- grammar_issues: èªæ³•å•é¡Œåˆ—è¡¨\n",
        "- clarity_issues: æ¸…æ™°åº¦å•é¡Œåˆ—è¡¨\n",
        "- suggestions: èªè¨€æ”¹é€²å»ºè­°\n",
        "\"\"\"\n",
        "        \n",
        "        return self._get_review_response(prompt)\n",
        "    \n",
        "    def _get_review_response(self, prompt: str) -> Dict[str, Any]:\n",
        "        \"\"\"ç²å–è©•å¯©å›æ‡‰\"\"\"\n",
        "        try:\n",
        "            response = ollama.chat(\n",
        "                model=self.model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                options={\"temperature\": 0.3}\n",
        "            )\n",
        "            \n",
        "            content = response['message']['content']\n",
        "            \n",
        "            try:\n",
        "                json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
        "                if json_match:\n",
        "                    result = json.loads(json_match.group())\n",
        "                else:\n",
        "                    result = {\"raw_output\": content, \"readability_score\": 5}\n",
        "            except json.JSONDecodeError:\n",
        "                result = {\"raw_output\": content, \"readability_score\": 5}\n",
        "            \n",
        "            return result\n",
        "            \n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e), \"readability_score\": 0}\n",
        "\n",
        "class BiasReviewer:\n",
        "    \"\"\"åè¦‹æª¢æŸ¥è©•å¯©å“¡\"\"\"\n",
        "    \n",
        "    def __init__(self, model: str):\n",
        "        self.model = model\n",
        "        \n",
        "    def review(self, items: List[str]) -> Dict[str, Any]:\n",
        "        \"\"\"æª¢æŸ¥äººå£å­¸åè¦‹\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "ä½ æ˜¯æ¸¬é©—åè¦‹æª¢æŸ¥å°ˆå®¶ã€‚è«‹æª¢æŸ¥ä»¥ä¸‹æ¸¬é©—é¡Œç›®æ˜¯å¦å­˜åœ¨äººå£å­¸åè¦‹ã€‚\n",
        "\n",
        "é¡Œç›®åˆ—è¡¨:\n",
        "{json.dumps(items, ensure_ascii=False, indent=2)}\n",
        "\n",
        "è«‹æª¢æŸ¥æ˜¯å¦å­˜åœ¨ä»¥ä¸‹åè¦‹ï¼š\n",
        "1. æ€§åˆ¥åè¦‹\n",
        "2. å¹´é½¡åè¦‹  \n",
        "3. æ–‡åŒ–åè¦‹\n",
        "4. ç¤¾ç¶“åœ°ä½åè¦‹\n",
        "5. å…¶ä»–æ­§è¦–æ€§å…§å®¹\n",
        "\n",
        "è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºæª¢æŸ¥çµæœï¼ŒåŒ…å«ï¼š\n",
        "- bias_score: åè¦‹ç¨‹åº¦ (1-10, 10è¡¨ç¤ºç„¡åè¦‹)\n",
        "- detected_biases: ç™¼ç¾çš„åè¦‹é¡å‹åˆ—è¡¨\n",
        "- problematic_items: æœ‰å•é¡Œçš„é¡Œç›®\n",
        "- suggestions: æ¶ˆé™¤åè¦‹çš„å»ºè­°\n",
        "\"\"\"\n",
        "        \n",
        "        return self._get_review_response(prompt)\n",
        "    \n",
        "    def _get_review_response(self, prompt: str) -> Dict[str, Any]:\n",
        "        \"\"\"ç²å–è©•å¯©å›æ‡‰\"\"\"\n",
        "        try:\n",
        "            response = ollama.chat(\n",
        "                model=self.model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                options={\"temperature\": 0.3}\n",
        "            )\n",
        "            \n",
        "            content = response['message']['content']\n",
        "            \n",
        "            try:\n",
        "                json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
        "                if json_match:\n",
        "                    result = json.loads(json_match.group())\n",
        "                else:\n",
        "                    result = {\"raw_output\": content, \"bias_score\": 5}\n",
        "            except json.JSONDecodeError:\n",
        "                result = {\"raw_output\": content, \"bias_score\": 5}\n",
        "            \n",
        "            return result\n",
        "            \n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e), \"bias_score\": 0}\n",
        "\n",
        "class MetaReviewer:\n",
        "    \"\"\"å…ƒè©•å¯©å“¡ï¼Œæ•´åˆæ‰€æœ‰è©•å¯©çµæœ\"\"\"\n",
        "    \n",
        "    def __init__(self, model: str):\n",
        "        self.model = model\n",
        "        \n",
        "    def integrate_reviews(self, reviews: Dict[str, Any], items: List[str]) -> Dict[str, Any]:\n",
        "        \"\"\"æ•´åˆæ‰€æœ‰è©•å¯©çµæœ\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "ä½ æ˜¯æ¸¬é©—è©•å¯©çš„è³‡æ·±å°ˆå®¶ã€‚è«‹æ•´åˆä»¥ä¸‹å„å€‹è©•å¯©å“¡çš„è©•å¯©çµæœï¼Œçµ¦å‡ºç¶œåˆè©•åƒ¹å’Œæ”¹é€²å»ºè­°ã€‚\n",
        "\n",
        "åŸå§‹é¡Œç›®:\n",
        "{json.dumps(items, ensure_ascii=False, indent=2)}\n",
        "\n",
        "å„è©•å¯©å“¡çµæœ:\n",
        "å…§å®¹æ•ˆåº¦è©•å¯©: {json.dumps(reviews.get('content_review', {}), ensure_ascii=False, indent=2)}\n",
        "èªè¨€å­¸è©•å¯©: {json.dumps(reviews.get('linguistic_review', {}), ensure_ascii=False, indent=2)}\n",
        "åè¦‹æª¢æŸ¥è©•å¯©: {json.dumps(reviews.get('bias_review', {}), ensure_ascii=False, indent=2)}\n",
        "\n",
        "è«‹æä¾›ï¼š\n",
        "1. ç¶œåˆè©•åˆ† (1-10)\n",
        "2. ä¸»è¦å„ªé»\n",
        "3. ä¸»è¦å•é¡Œ\n",
        "4. å„ªå…ˆæ”¹é€²å»ºè­°\n",
        "5. æ˜¯å¦å»ºè­°é‡æ–°ç”Ÿæˆ\n",
        "\n",
        "è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºï¼ŒåŒ…å«ï¼š\n",
        "- overall_score: ç¶œåˆåˆ†æ•¸\n",
        "- strengths: ä¸»è¦å„ªé»åˆ—è¡¨\n",
        "- major_issues: ä¸»è¦å•é¡Œåˆ—è¡¨\n",
        "- recommendations: æ”¹é€²å»ºè­°åˆ—è¡¨\n",
        "- regenerate_recommended: æ˜¯å¦å»ºè­°é‡æ–°ç”Ÿæˆ (boolean)\n",
        "\"\"\"\n",
        "        \n",
        "        return self._get_review_response(prompt)\n",
        "    \n",
        "    def _get_review_response(self, prompt: str) -> Dict[str, Any]:\n",
        "        \"\"\"ç²å–è©•å¯©å›æ‡‰\"\"\"\n",
        "        try:\n",
        "            response = ollama.chat(\n",
        "                model=self.model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                options={\"temperature\": 0.3}\n",
        "            )\n",
        "            \n",
        "            content = response['message']['content']\n",
        "            \n",
        "            try:\n",
        "                json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
        "                if json_match:\n",
        "                    result = json.loads(json_match.group())\n",
        "                else:\n",
        "                    result = {\"raw_output\": content, \"overall_score\": 5}\n",
        "            except json.JSONDecodeError:\n",
        "                result = {\"raw_output\": content, \"overall_score\": 5}\n",
        "            \n",
        "            return result\n",
        "            \n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e), \"overall_score\": 0}\n",
        "\n",
        "# å»ºç«‹è©•å¯©ä»£ç†äººå¯¦ä¾‹\n",
        "critic_agent = CriticAgent()\n",
        "print(\"âœ… CriticAgent å·²åˆå§‹åŒ–å®Œæˆï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS4h-9H9CDGw"
      },
      "source": [
        "## è³‡æ–™åˆ†æ\n",
        "\n",
        "æ ¹æ“šå‰è¿°çš„ç†è«–æ¶æ§‹è‡ªå‹•é€²è¡Œ Factor analysisã€‚\n",
        "\n",
        "ï¼ˆMCP æ‡‰è©²ç”¨åœ¨é€™è£¡ï¼Œè®“æ¨¡å‹å‚³å…¥EFA, CFA çš„å‡½å¼åƒæ•¸ï¼Œä¸¦èª¿ç”¨å‡½æ•¸å–å¾—çµæœã€‚ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m7kLMPE7Fhma"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… DataAnalysisPipeline å·²åˆå§‹åŒ–å®Œæˆï¼\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "class DataAnalysisPipeline:\n",
        "    \"\"\"\n",
        "    è³‡æ–™åˆ†æç®¡ç·šï¼Œç”¨æ–¼åˆ†ææ¸¬é©—é¡Œç›®çš„å¿ƒç†è¨ˆé‡ç‰¹æ€§\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.factor_analysis = None\n",
        "        self.data = None\n",
        "        self.scaled_data = None\n",
        "        \n",
        "    def load_simulated_data(self, n_participants: int = 200, n_items: int = 10) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        ç”Ÿæˆæ¨¡æ“¬æ¸¬é©—è³‡æ–™ï¼ˆå¯¦éš›ä½¿ç”¨æ™‚æ‡‰è¼‰å…¥çœŸå¯¦è³‡æ–™ï¼‰\n",
        "        \n",
        "        Args:\n",
        "            n_participants: å—è©¦è€…æ•¸é‡\n",
        "            n_items: é¡Œç›®æ•¸é‡\n",
        "            \n",
        "        Returns:\n",
        "            æ¨¡æ“¬çš„æ¸¬é©—åæ‡‰è³‡æ–™\n",
        "        \"\"\"\n",
        "        # ç”Ÿæˆæ¨¡æ“¬è³‡æ–™ï¼šå‡è¨­æœ‰ä¸€å€‹æ½›åœ¨å› å­\n",
        "        np.random.seed(42)\n",
        "        \n",
        "        # æ½›åœ¨å› å­åˆ†æ•¸\n",
        "        latent_factor = np.random.normal(0, 1, n_participants)\n",
        "        \n",
        "        # é¡Œç›®åƒæ•¸\n",
        "        item_loadings = np.random.uniform(0.3, 0.8, n_items)\n",
        "        item_difficulties = np.random.uniform(-2, 2, n_items)\n",
        "        \n",
        "        # ç”Ÿæˆåæ‡‰è³‡æ–™ï¼ˆä½¿ç”¨ Rasch æ¨¡å‹æ¦‚å¿µä½†ç°¡åŒ–ç‚ºé€£çºŒåˆ†æ•¸ï¼‰\n",
        "        responses = []\n",
        "        for i in range(n_items):\n",
        "            # ç°¡åŒ–çš„é …ç›®åæ‡‰ï¼šå› å­è² è·é‡ * æ½›åœ¨å› å­ + é›£åº¦ + éš¨æ©Ÿèª¤å·®\n",
        "            item_scores = (item_loadings[i] * latent_factor + \n",
        "                          item_difficulties[i] + \n",
        "                          np.random.normal(0, 0.3, n_participants))\n",
        "            # è½‰æ›ç‚º 1-5 åˆ†çš„æå…‹ç‰¹é‡è¡¨\n",
        "            item_scores = np.clip(np.round(3 + item_scores), 1, 5)\n",
        "            responses.append(item_scores)\n",
        "        \n",
        "        # å»ºç«‹ DataFrame\n",
        "        data = pd.DataFrame(\n",
        "            np.array(responses).T,\n",
        "            columns=[f'Item_{i+1}' for i in range(n_items)]\n",
        "        )\n",
        "        \n",
        "        self.data = data\n",
        "        return data\n",
        "    \n",
        "    def exploratory_factor_analysis(self, n_factors: int = 1) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        é€²è¡Œæ¢ç´¢æ€§å› å­åˆ†æ (EFA)\n",
        "        \n",
        "        Args:\n",
        "            n_factors: å› å­æ•¸é‡\n",
        "            \n",
        "        Returns:\n",
        "            å› å­åˆ†æçµæœ\n",
        "        \"\"\"\n",
        "        if self.data is None:\n",
        "            return {\"error\": \"è«‹å…ˆè¼‰å…¥è³‡æ–™\"}\n",
        "        \n",
        "        try:\n",
        "            # æ¨™æº–åŒ–è³‡æ–™\n",
        "            self.scaled_data = self.scaler.fit_transform(self.data)\n",
        "            \n",
        "            # å› å­åˆ†æ\n",
        "            self.factor_analysis = FactorAnalysis(n_components=n_factors, random_state=42)\n",
        "            factor_scores = self.factor_analysis.fit_transform(self.scaled_data)\n",
        "            \n",
        "            # å› å­è² è·é‡\n",
        "            loadings = self.factor_analysis.components_.T\n",
        "            \n",
        "            # è¨ˆç®—è§£é‡‹è®Šç•°é‡\n",
        "            explained_variance = np.var(factor_scores, axis=0)\n",
        "            explained_variance_ratio = explained_variance / np.sum(explained_variance)\n",
        "            \n",
        "            # è¨ˆç®—é …ç›®é–“ç›¸é—œ\n",
        "            correlation_matrix = np.corrcoef(self.data.T)\n",
        "            \n",
        "            # ä¿¡åº¦åˆ†æï¼ˆCronbach's Alphaï¼‰\n",
        "            alpha = self._calculate_cronbach_alpha()\n",
        "            \n",
        "            results = {\n",
        "                \"n_factors\": n_factors,\n",
        "                \"factor_loadings\": loadings.tolist(),\n",
        "                \"factor_loadings_df\": pd.DataFrame(\n",
        "                    loadings, \n",
        "                    columns=[f'Factor_{i+1}' for i in range(n_factors)],\n",
        "                    index=self.data.columns\n",
        "                ),\n",
        "                \"explained_variance_ratio\": explained_variance_ratio.tolist(),\n",
        "                \"correlation_matrix\": correlation_matrix.tolist(),\n",
        "                \"cronbach_alpha\": alpha,\n",
        "                \"factor_scores\": factor_scores,\n",
        "                \"item_statistics\": self._calculate_item_statistics()\n",
        "            }\n",
        "            \n",
        "            return results\n",
        "            \n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"å› å­åˆ†æå¤±æ•—: {str(e)}\"}\n",
        "    \n",
        "    def _calculate_cronbach_alpha(self) -> float:\n",
        "        \"\"\"è¨ˆç®— Cronbach's Alpha ä¿¡åº¦ä¿‚æ•¸\"\"\"\n",
        "        if self.data is None:\n",
        "            return 0.0\n",
        "        \n",
        "        # é …ç›®æ•¸é‡\n",
        "        k = self.data.shape[1]\n",
        "        \n",
        "        # é …ç›®è®Šç•°æ•¸\n",
        "        item_variances = self.data.var(axis=0, ddof=1)\n",
        "        \n",
        "        # ç¸½åˆ†è®Šç•°æ•¸\n",
        "        total_variance = self.data.sum(axis=1).var(ddof=1)\n",
        "        \n",
        "        # Cronbach's Alpha å…¬å¼\n",
        "        alpha = (k / (k - 1)) * (1 - item_variances.sum() / total_variance)\n",
        "        \n",
        "        return alpha\n",
        "    \n",
        "    def _calculate_item_statistics(self) -> Dict[str, Any]:\n",
        "        \"\"\"è¨ˆç®—é¡Œç›®çµ±è¨ˆé‡\"\"\"\n",
        "        if self.data is None:\n",
        "            return {}\n",
        "        \n",
        "        stats = {\n",
        "            \"means\": self.data.mean().to_dict(),\n",
        "            \"std_devs\": self.data.std().to_dict(),\n",
        "            \"skewness\": self.data.skew().to_dict(),\n",
        "            \"kurtosis\": self.data.kurtosis().to_dict(),\n",
        "        }\n",
        "        \n",
        "        # é …ç›®-ç¸½åˆ†ç›¸é—œ\n",
        "        total_scores = self.data.sum(axis=1)\n",
        "        item_total_correlations = {}\n",
        "        for col in self.data.columns:\n",
        "            # ä¿®æ­£çš„é …ç›®-ç¸½åˆ†ç›¸é—œï¼ˆæ’é™¤è©²é¡Œç›®æœ¬èº«ï¼‰\n",
        "            corrected_total = total_scores - self.data[col]\n",
        "            correlation = np.corrcoef(self.data[col], corrected_total)[0, 1]\n",
        "            item_total_correlations[col] = correlation\n",
        "        \n",
        "        stats[\"item_total_correlations\"] = item_total_correlations\n",
        "        \n",
        "        return stats\n",
        "    \n",
        "    def generate_analysis_report(self, efa_results: Dict[str, Any]) -> str:\n",
        "        \"\"\"ç”Ÿæˆåˆ†æå ±å‘Š\"\"\"\n",
        "        if \"error\" in efa_results:\n",
        "            return f\"åˆ†æéŒ¯èª¤: {efa_results['error']}\"\n",
        "        \n",
        "        report = f\"\"\"\n",
        "ğŸ“Š æ¸¬é©—å¿ƒç†è¨ˆé‡åˆ†æå ±å‘Š\n",
        "{'='*50}\n",
        "\n",
        "ğŸ”¢ åŸºæœ¬è³‡è¨Š:\n",
        "- æ¨£æœ¬æ•¸: {self.data.shape[0]}\n",
        "- é¡Œç›®æ•¸: {self.data.shape[1]}\n",
        "- å› å­æ•¸: {efa_results['n_factors']}\n",
        "\n",
        "ğŸ“ˆ ä¿¡åº¦åˆ†æ:\n",
        "- Cronbach's Alpha: {efa_results['cronbach_alpha']:.3f}\n",
        "\n",
        "ğŸ¯ å› å­åˆ†æçµæœ:\n",
        "è§£é‡‹è®Šç•°é‡æ¯”ä¾‹: {[f'{ratio:.3f}' for ratio in efa_results['explained_variance_ratio']]}\n",
        "\n",
        "ğŸ“‹ å› å­è² è·é‡:\n",
        "{efa_results['factor_loadings_df'].round(3).to_string()}\n",
        "\n",
        "ğŸ“Š é¡Œç›®çµ±è¨ˆ:\n",
        "\"\"\"\n",
        "        \n",
        "        item_stats = efa_results['item_statistics']\n",
        "        for item in self.data.columns:\n",
        "            report += f\"\\n{item}:\"\n",
        "            report += f\"  å¹³å‡æ•¸: {item_stats['means'][item]:.2f}\"\n",
        "            report += f\"  æ¨™æº–å·®: {item_stats['std_devs'][item]:.2f}\"\n",
        "            report += f\"  é …ç›®-ç¸½åˆ†ç›¸é—œ: {item_stats['item_total_correlations'][item]:.3f}\"\n",
        "        \n",
        "        # è©•ä¼°å»ºè­°\n",
        "        report += f\"\\n\\nğŸ’¡ è©•ä¼°å»ºè­°:\\n\"\n",
        "        \n",
        "        if efa_results['cronbach_alpha'] >= 0.8:\n",
        "            report += \"âœ… ä¿¡åº¦è‰¯å¥½ (Î± â‰¥ 0.8)\\n\"\n",
        "        elif efa_results['cronbach_alpha'] >= 0.7:\n",
        "            report += \"âš ï¸ ä¿¡åº¦å°šå¯ (0.7 â‰¤ Î± < 0.8)ï¼Œå¯è€ƒæ…®æ”¹é€²\\n\"\n",
        "        else:\n",
        "            report += \"âŒ ä¿¡åº¦åä½ (Î± < 0.7)ï¼Œå»ºè­°é‡æ–°æª¢è¦–é¡Œç›®\\n\"\n",
        "        \n",
        "        # æª¢æŸ¥é …ç›®-ç¸½åˆ†ç›¸é—œ\n",
        "        low_correlation_items = [\n",
        "            item for item, corr in item_stats['item_total_correlations'].items()\n",
        "            if corr < 0.3\n",
        "        ]\n",
        "        \n",
        "        if low_correlation_items:\n",
        "            report += f\"âš ï¸ ä»¥ä¸‹é¡Œç›®èˆ‡ç¸½åˆ†ç›¸é—œåä½ï¼Œå»ºè­°æª¢è¦–: {', '.join(low_correlation_items)}\\n\"\n",
        "        else:\n",
        "            report += \"âœ… æ‰€æœ‰é¡Œç›®èˆ‡ç¸½åˆ†ç›¸é—œè‰¯å¥½\\n\"\n",
        "        \n",
        "        return report\n",
        "\n",
        "# å»ºç«‹è³‡æ–™åˆ†æç®¡ç·šå¯¦ä¾‹\n",
        "analysis_pipeline = DataAnalysisPipeline()\n",
        "print(\"âœ… DataAnalysisPipeline å·²åˆå§‹åŒ–å®Œæˆï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹\n",
        "\n",
        "ç¾åœ¨è®“æˆ‘å€‘å°‡æ‰€æœ‰çµ„ä»¶æ•´åˆï¼Œå±•ç¤ºå®Œæ•´çš„ LM-AIG å·¥ä½œæµç¨‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… LM-AIG å®Œæ•´ç³»çµ±å·²åˆå§‹åŒ–ï¼\n"
          ]
        }
      ],
      "source": [
        "class LM_AIG_System:\n",
        "    \"\"\"\n",
        "    å®Œæ•´çš„ LM-AIG ç³»çµ±ï¼Œæ•´åˆé¡Œç›®ç”Ÿæˆã€è©•å¯©å’Œè³‡æ–™åˆ†æ\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.item_writer = ItemWritingAgent()\n",
        "        self.critic = CriticAgent()\n",
        "        self.analyzer = DataAnalysisPipeline()\n",
        "        \n",
        "    def run_complete_workflow(self, specifications: str, num_items: int = 5, \n",
        "                            max_iterations: int = 3) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        åŸ·è¡Œå®Œæ•´çš„å·¥ä½œæµç¨‹\n",
        "        \n",
        "        Args:\n",
        "            specifications: é¡Œç›®è¦æ ¼\n",
        "            num_items: é¡Œç›®æ•¸é‡\n",
        "            max_iterations: æœ€å¤§æ”¹é€²è¿­ä»£æ¬¡æ•¸\n",
        "            \n",
        "        Returns:\n",
        "            å®Œæ•´çš„å·¥ä½œæµç¨‹çµæœ\n",
        "        \"\"\"\n",
        "        workflow_results = {\n",
        "            \"original_specifications\": specifications,\n",
        "            \"iterations\": [],\n",
        "            \"final_items\": None,\n",
        "            \"analysis_results\": None\n",
        "        }\n",
        "        \n",
        "        print(f\"ğŸš€ é–‹å§‹ LM-AIG å·¥ä½œæµç¨‹\")\n",
        "        print(f\"ğŸ“ è¦æ ¼: {specifications}\")\n",
        "        print(f\"ğŸ”¢ ç›®æ¨™é¡Œç›®æ•¸é‡: {num_items}\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        current_items = None\n",
        "        \n",
        "        for iteration in range(max_iterations):\n",
        "            print(f\"\\nğŸ”„ ç¬¬ {iteration + 1} æ¬¡è¿­ä»£\")\n",
        "            \n",
        "            # ç¬¬ä¸€æ¬¡è¿­ä»£ï¼šç”Ÿæˆé¡Œç›®ï¼›å¾ŒçºŒè¿­ä»£ï¼šæ”¹é€²é¡Œç›®\n",
        "            if iteration == 0:\n",
        "                print(\"ğŸ“ ç”Ÿæˆåˆå§‹é¡Œç›®...\")\n",
        "                generation_result = self.item_writer.generate_items(specifications, num_items)\n",
        "            else:\n",
        "                print(\"ğŸ”§ æ ¹æ“šè©•å¯©å»ºè­°æ”¹é€²é¡Œç›®...\")\n",
        "                feedback = previous_review.get(\"recommendations\", [\"è«‹æ”¹é€²é¡Œç›®å“è³ª\"])\n",
        "                generation_result = self.item_writer.refine_items(current_items, \n",
        "                                                               str(feedback))\n",
        "            \n",
        "            if \"error\" in generation_result:\n",
        "                print(f\"âŒ ç”ŸæˆéŒ¯èª¤: {generation_result['error']}\")\n",
        "                continue\n",
        "                \n",
        "            current_items = generation_result.get(\"items\", [])\n",
        "            print(f\"âœ… å·²ç”Ÿæˆ {len(current_items)} å€‹é¡Œç›®\")\n",
        "            \n",
        "            # è©•å¯©é¡Œç›®\n",
        "            print(\"ğŸ” è©•å¯©é¡Œç›®å“è³ª...\")\n",
        "            review_result = self.critic.review_items(current_items, \n",
        "                                                   specifications)\n",
        "            \n",
        "            iteration_result = {\n",
        "                \"iteration\": iteration + 1,\n",
        "                \"generated_items\": current_items,\n",
        "                \"generation_result\": generation_result,\n",
        "                \"review_result\": review_result,\n",
        "                \"overall_score\": review_result.get(\"overall_score\", 0)\n",
        "            }\n",
        "            \n",
        "            workflow_results[\"iterations\"].append(iteration_result)\n",
        "            \n",
        "            print(f\"ğŸ“Š ç¶œåˆè©•åˆ†: {review_result.get('overall_score', 0)}/10\")\n",
        "            \n",
        "            # æª¢æŸ¥æ˜¯å¦é”åˆ°æ»¿æ„æ¨™æº–\n",
        "            if review_result.get(\"overall_score\", 0) >= 7:  # 7åˆ†ä»¥ä¸Šç®—åŠæ ¼\n",
        "                print(\"âœ… é¡Œç›®å“è³ªå·²é”æ¨™æº–ï¼ŒçµæŸè¿­ä»£\")\n",
        "                break\n",
        "            elif not review_result.get(\"meta_review\", {}).get(\"regenerate_recommended\", True):\n",
        "                print(\"âœ… è©•å¯©å»ºè­°ç¹¼çºŒä½¿ç”¨ç•¶å‰ç‰ˆæœ¬\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"âš ï¸ éœ€è¦ç¹¼çºŒæ”¹é€²\")\n",
        "                previous_review = review_result.get(\"meta_review\", {})\n",
        "        \n",
        "        workflow_results[\"final_items\"] = current_items\n",
        "        \n",
        "        # é€²è¡Œè³‡æ–™åˆ†æï¼ˆä½¿ç”¨æ¨¡æ“¬è³‡æ–™ï¼‰\n",
        "        if current_items:\n",
        "            print(\"\\nğŸ“Š é€²è¡Œå¿ƒç†è¨ˆé‡åˆ†æ...\")\n",
        "            simulated_data = self.analyzer.load_simulated_data(\n",
        "                n_participants=200, \n",
        "                n_items=len(current_items)\n",
        "            )\n",
        "            \n",
        "            efa_results = self.analyzer.exploratory_factor_analysis(n_factors=1)\n",
        "            analysis_report = self.analyzer.generate_analysis_report(efa_results)\n",
        "            \n",
        "            workflow_results[\"analysis_results\"] = {\n",
        "                \"efa_results\": efa_results,\n",
        "                \"analysis_report\": analysis_report,\n",
        "                \"simulated_data_shape\": simulated_data.shape\n",
        "            }\n",
        "            \n",
        "            print(\"âœ… åˆ†æå®Œæˆ\")\n",
        "        \n",
        "        return workflow_results\n",
        "    \n",
        "    def display_results(self, results: Dict[str, Any]):\n",
        "        \"\"\"é¡¯ç¤ºå·¥ä½œæµç¨‹çµæœ\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ğŸ“‹ LM-AIG ç³»çµ±åŸ·è¡Œçµæœ\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        print(f\"\\nğŸ“ åŸå§‹è¦æ ¼: {results['original_specifications']}\")\n",
        "        print(f\"ğŸ”„ è¿­ä»£æ¬¡æ•¸: {len(results['iterations'])}\")\n",
        "        \n",
        "        # é¡¯ç¤ºæœ€çµ‚é¡Œç›®\n",
        "        final_items = results.get(\"final_items\", [])\n",
        "        print(f\"\\nğŸ“Š æœ€çµ‚é¡Œç›® ({len(final_items)} å€‹):\")\n",
        "        for i, item in enumerate(final_items, 1):\n",
        "            print(f\"{i:2}. {item}\")\n",
        "        \n",
        "        # é¡¯ç¤ºè©•å¯©æ­·ç¨‹\n",
        "        print(f\"\\nğŸ“ˆ è©•åˆ†æ­·ç¨‹:\")\n",
        "        for iteration in results[\"iterations\"]:\n",
        "            score = iteration.get(\"overall_score\", 0)\n",
        "            print(f\"  ç¬¬ {iteration['iteration']} æ¬¡è¿­ä»£: {score}/10\")\n",
        "        \n",
        "        # é¡¯ç¤ºåˆ†æçµæœ\n",
        "        if results.get(\"analysis_results\"):\n",
        "            print(\"\\n\" + \"=\"*40)\n",
        "            print(\"ğŸ“Š å¿ƒç†è¨ˆé‡åˆ†æçµæœ\")\n",
        "            print(\"=\"*40)\n",
        "            print(results[\"analysis_results\"][\"analysis_report\"])\n",
        "\n",
        "# å»ºç«‹å®Œæ•´ç³»çµ±\n",
        "lm_aig_system = LM_AIG_System()\n",
        "print(\"âœ… LM-AIG å®Œæ•´ç³»çµ±å·²åˆå§‹åŒ–ï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ç³»çµ±æ¼”ç¤º\n",
        "\n",
        "è®“æˆ‘å€‘é‹è¡Œä¸€å€‹å¯¦éš›çš„ä¾‹å­ä¾†æ¸¬è©¦ç³»çµ±ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ é–‹å§‹æ¼”ç¤ºï¼šè‡ªæˆ‘æ•ˆèƒ½é‡è¡¨ç”Ÿæˆ\n",
            "============================================================\n",
            "ğŸš€ é–‹å§‹ LM-AIG å·¥ä½œæµç¨‹\n",
            "ğŸ“ è¦æ ¼: \n",
            "è«‹ç”Ÿæˆä¸€å€‹ã€Œè‡ªæˆ‘æ•ˆèƒ½ã€(Self-Efficacy) å¿ƒç†æ¸¬é©—é‡è¡¨çš„é¡Œç›®ã€‚\n",
            "\n",
            "è¦æ±‚ï¼š\n",
            "1. æ¸¬é‡å€‹é«”å°è‡ªå·±èƒ½åŠ›çš„ä¿¡å¿ƒç¨‹åº¦\n",
            "2. ä½¿ç”¨ 5 é»æå…‹ç‰¹é‡è¡¨ (1=å®Œå…¨ä¸åŒæ„, 5=å®Œå…¨åŒæ„)\n",
            "3. é¡Œç›®æ‡‰æ¶µè“‹ä¸åŒç”Ÿæ´»é ˜åŸŸ (å­¸ç¿’ã€å·¥ä½œã€ç¤¾äº¤ç­‰)\n",
            "4. èªè¨€ç°¡æ½”æ˜ç¢ºï¼Œé©åˆå¤§å­¸ç”Ÿå¡«ç­”\n",
            "5. é¿å…è² é¢é™³è¿°å’Œé›™é‡å¦å®š\n",
            "6. æ¯å€‹é¡Œç›®æ¸¬é‡è‡ªæˆ‘æ•ˆèƒ½çš„ä¸åŒé¢å‘\n",
            "\n",
            "å¿ƒç†å­¸ç†è«–åŸºç¤ï¼š\n",
            "- Bandura çš„è‡ªæˆ‘æ•ˆèƒ½ç†è«–\n",
            "- æ¸¬é‡å€‹é«”å°å®Œæˆç‰¹å®šä»»å‹™æˆ–é¢å°æŒ‘æˆ°çš„ä¿¡å¿ƒ\n",
            "\n",
            "ğŸ”¢ ç›®æ¨™é¡Œç›®æ•¸é‡: 8\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”„ ç¬¬ 1 æ¬¡è¿­ä»£\n",
            "ğŸ“ ç”Ÿæˆåˆå§‹é¡Œç›®...\n",
            "âœ… å·²ç”Ÿæˆ 8 å€‹é¡Œç›®\n",
            "ğŸ” è©•å¯©é¡Œç›®å“è³ª...\n",
            "ğŸ” é–‹å§‹å…¨é¢è©•å¯©æ¸¬é©—é¡Œç›®...\n",
            "âœ… å·²ç”Ÿæˆ 8 å€‹é¡Œç›®\n",
            "ğŸ” è©•å¯©é¡Œç›®å“è³ª...\n",
            "ğŸ” é–‹å§‹å…¨é¢è©•å¯©æ¸¬é©—é¡Œç›®...\n"
          ]
        }
      ],
      "source": [
        "# æ¼”ç¤ºï¼šç”Ÿæˆè‡ªæˆ‘æ•ˆèƒ½é‡è¡¨é¡Œç›®\n",
        "\n",
        "# å®šç¾©æ¸¬é©—è¦æ ¼\n",
        "specifications = \"\"\"\n",
        "è«‹ç”Ÿæˆä¸€å€‹ã€Œè‡ªæˆ‘æ•ˆèƒ½ã€(Self-Efficacy) å¿ƒç†æ¸¬é©—é‡è¡¨çš„é¡Œç›®ã€‚\n",
        "\n",
        "è¦æ±‚ï¼š\n",
        "1. æ¸¬é‡å€‹é«”å°è‡ªå·±èƒ½åŠ›çš„ä¿¡å¿ƒç¨‹åº¦\n",
        "2. ä½¿ç”¨ 5 é»æå…‹ç‰¹é‡è¡¨ (1=å®Œå…¨ä¸åŒæ„, 5=å®Œå…¨åŒæ„)\n",
        "3. é¡Œç›®æ‡‰æ¶µè“‹ä¸åŒç”Ÿæ´»é ˜åŸŸ (å­¸ç¿’ã€å·¥ä½œã€ç¤¾äº¤ç­‰)\n",
        "4. èªè¨€ç°¡æ½”æ˜ç¢ºï¼Œé©åˆå¤§å­¸ç”Ÿå¡«ç­”\n",
        "5. é¿å…è² é¢é™³è¿°å’Œé›™é‡å¦å®š\n",
        "6. æ¯å€‹é¡Œç›®æ¸¬é‡è‡ªæˆ‘æ•ˆèƒ½çš„ä¸åŒé¢å‘\n",
        "\n",
        "å¿ƒç†å­¸ç†è«–åŸºç¤ï¼š\n",
        "- Bandura çš„è‡ªæˆ‘æ•ˆèƒ½ç†è«–\n",
        "- æ¸¬é‡å€‹é«”å°å®Œæˆç‰¹å®šä»»å‹™æˆ–é¢å°æŒ‘æˆ°çš„ä¿¡å¿ƒ\n",
        "\"\"\"\n",
        "\n",
        "print(\"ğŸ¯ é–‹å§‹æ¼”ç¤ºï¼šè‡ªæˆ‘æ•ˆèƒ½é‡è¡¨ç”Ÿæˆ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# é‹è¡Œå®Œæ•´å·¥ä½œæµç¨‹\n",
        "demo_results = lm_aig_system.run_complete_workflow(\n",
        "    specifications=specifications,\n",
        "    num_items=8,\n",
        "    max_iterations=2\n",
        ")\n",
        "\n",
        "# é¡¯ç¤ºçµæœ\n",
        "lm_aig_system.display_results(demo_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## å–®ç¨çµ„ä»¶ä½¿ç”¨ç¤ºä¾‹\n",
        "\n",
        "æ‚¨ä¹Ÿå¯ä»¥å–®ç¨ä½¿ç”¨å„å€‹çµ„ä»¶é€²è¡Œæ¸¬è©¦ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç¤ºä¾‹ 1: å–®ç¨ä½¿ç”¨é¡Œç›®ç”Ÿæˆå™¨\n",
        "print(\"ğŸ“ ç¤ºä¾‹ 1: å–®ç¨ç”Ÿæˆé¡Œç›®\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "simple_spec = \"ç”Ÿæˆ 3 å€‹æ¸¬é‡ç„¦æ…®ç¨‹åº¦çš„æå…‹ç‰¹é‡è¡¨é¡Œç›®\"\n",
        "generated = item_writer.generate_items(simple_spec, num_items=3)\n",
        "\n",
        "print(f\"ç”Ÿæˆçµæœ: {json.dumps(generated, ensure_ascii=False, indent=2)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# ç¤ºä¾‹ 2: å–®ç¨ä½¿ç”¨è©•å¯©ç³»çµ±\n",
        "print(\"ğŸ” ç¤ºä¾‹ 2: è©•å¯©é¡Œç›®å“è³ª\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "sample_items = [\n",
        "    \"æˆ‘ç¶“å¸¸æ„Ÿåˆ°æ“”å¿ƒæˆ–ç·Šå¼µ\",\n",
        "    \"æˆ‘å¾ˆé›£æ”¾é¬†è‡ªå·±\",\n",
        "    \"æˆ‘å°æœªä¾†æ„Ÿåˆ°ææ‡¼\"\n",
        "]\n",
        "\n",
        "review_result = critic_agent.review_items(sample_items, \"ç„¦æ…®ç¨‹åº¦\")\n",
        "print(f\"è©•å¯©çµæœç¶œåˆè©•åˆ†: {review_result.get('overall_score', 0)}/10\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# ç¤ºä¾‹ 3: å–®ç¨ä½¿ç”¨è³‡æ–™åˆ†æ\n",
        "print(\"ğŸ“Š ç¤ºä¾‹ 3: å¿ƒç†è¨ˆé‡åˆ†æ\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# è¼‰å…¥æ¨¡æ“¬è³‡æ–™ä¸¦é€²è¡Œåˆ†æ\n",
        "data = analysis_pipeline.load_simulated_data(n_participants=100, n_items=6)\n",
        "print(f\"æ¨¡æ“¬è³‡æ–™å½¢ç‹€: {data.shape}\")\n",
        "print(\"å‰ 5 è¡Œè³‡æ–™:\")\n",
        "print(data.head())\n",
        "\n",
        "# é€²è¡Œå› å­åˆ†æ\n",
        "efa_results = analysis_pipeline.exploratory_factor_analysis(n_factors=1)\n",
        "if \"error\" not in efa_results:\n",
        "    print(f\"\\nCronbach's Alpha: {efa_results['cronbach_alpha']:.3f}\")\n",
        "    print(\"å› å­è² è·é‡:\")\n",
        "    print(efa_results['factor_loadings_df'].round(3))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
